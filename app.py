# ============================================================
# ğŸ“˜ ä½“è‚²æ–°é—»æ„ŸçŸ¥ç ”ç©¶é—®å·ç³»ç»Ÿï¼ˆé¡ºåºå¾ªç¯é—®å· + Google Sheets ä¸Šä¼ æ¯æ¡æ–°é—»æ‰“åˆ†ï¼‰
# ============================================================

import streamlit as st
import pandas as pd
import datetime, os, uuid, requests

# âœ… ä½ çš„ Google Apps Script Web App åœ°å€
GOOGLE_SCRIPT_URL = "https://script.google.com/macros/s/AKfycbzFJpJGK_pMcbRNzNFgLCl-dTLusdEXF_n03ElTiSpX7iCqebLtWFvPHPpcu4mPKxAyyQ/exec"

st.set_page_config(page_title="ä½“è‚²æ–°é—»æ„ŸçŸ¥ç ”ç©¶é—®å·", layout="wide")

# é—®å·æ–‡ä»¶ç›®å½•
QUESTION_DIR = "./generated_questionnaires"
files = sorted([f for f in os.listdir(QUESTION_DIR) if f.endswith('.xlsx')])
if not files:
    st.error("âŒ æœªæ£€æµ‹åˆ°é—®å·æ–‡ä»¶ï¼Œè¯·ç¡®è®¤ /generated_questionnaires/ ä¸‹å­˜åœ¨é—®å·æ–‡ä»¶ã€‚")
    st.stop()

# ========== å‡½æ•°ï¼šç¡®å®šå½“å‰åº”åˆ†é…å“ªä¸€ä»½é—®å· ==========
def get_current_questionnaire():
    if not os.path.exists("responses.csv"):
        return files[0]
    df = pd.read_csv("responses.csv")
    count_by_qid = df.groupby("questionnaire_id")["respondent_uuid"].nunique().to_dict()
    for f in files:
        qid = os.path.splitext(f)[0].replace("questionnaire_", "")
        filled = count_by_qid.get(qid, 0)
        if filled < 20:
            return f
    return files[0]  # å…¨éƒ¨æ»¡ 20 ä»½åˆ™é‡æ–°å¾ªç¯

# ========== é¡µé¢å†…å®¹ ==========
st.title("ä½“è‚²æ–°é—»æ„ŸçŸ¥ç ”ç©¶é—®å·")
st.markdown("""
æ‚¨å¥½ï¼æˆ‘ä»¬æ­£åœ¨ç ”ç©¶**ä½“è‚²æ–°é—»çš„å¸å¼•åŠ›ä¸çœŸå®æ€§æ„ŸçŸ¥**ï¼Œ
ç³»ç»Ÿä¼šä¾æ¬¡åˆ†é…é—®å·ï¼Œæ¯ä»½é—®å·æ”¶é›†æ»¡20ä»½åè‡ªåŠ¨åˆ‡æ¢ä¸‹ä¸€ä»½ã€‚
æ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼
""")
agree = st.checkbox("æˆ‘å·²ç†è§£å¹¶åŒæ„å‚ä¸")
if not agree:
    st.stop()

# é€‰æ‹©å½“å‰é—®å·ï¼ˆæŒ‰é¡ºåºï¼‰
chosen_file = get_current_questionnaire()
file_path = os.path.join(QUESTION_DIR, chosen_file)
df_questions = pd.read_excel(file_path)
qid = os.path.splitext(chosen_file)[0].replace("questionnaire_", "")
st.markdown(f"**å½“å‰é—®å·ç¼–å·ï¼š{qid}**ï¼ˆæ–‡ä»¶ï¼š{chosen_file}ï¼‰")
st.write(f"ï¼ˆæœ¬é—®å·åŒ…å« {len(df_questions)} æ¡æ–°é—»ï¼‰")

# ====== åŸºæœ¬ä¿¡æ¯ ======
st.header("ä¸€ã€åŸºæœ¬ä¿¡æ¯")
age = st.radio("1. æ‚¨çš„å¹´é¾„ï¼Ÿ", ["18-25å²", "26-35å²", "36-45å²", "46å²ä»¥ä¸Š"], key="age")
edu = st.radio("2. æ•™è‚²ç¨‹åº¦ï¼š", ["é«˜ä¸­åŠä»¥ä¸‹", "å¤§ä¸“", "æœ¬ç§‘", "ç¡•å£«åŠä»¥ä¸Š"], key="edu")
freq = st.radio("3. æ‚¨æ¯å‘¨é˜…è¯»åˆ°ä½“è‚²æ–°é—»çš„é¢‘ç‡ï¼Ÿ", ["<1æ¬¡", "1-3æ¬¡", "4-7æ¬¡", ">7æ¬¡"], key="freq")

if freq == "<1æ¬¡":
    st.warning("æ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼ç”±äºæ‚¨é˜…è¯»ä½“è‚²æ–°é—»é¢‘ç‡è¾ƒä½ï¼Œé—®å·åˆ°æ­¤ç»“æŸã€‚")
    st.stop()

# ====== æ–°é—»è¯„ä»·éƒ¨åˆ† ======
st.header("äºŒã€ä½“è‚²æ–°é—»è¯„ä»·")
responses = []
for i, row in df_questions.iterrows():
    slug = str(row.get("ID", i))
    st.subheader(f"æ–°é—» {slug}")
    st.write(row.get("title", "ï¼ˆç¼ºå¤±æ ‡é¢˜ï¼‰"))
    score = st.radio(
        "æ‚¨è®¤ä¸ºè¯¥ä½“è‚²æ–°é—»çš„çœŸå®æ€§å¦‚ä½•ï¼Ÿ",
        options=list(range(1, 11)),
        format_func=lambda x: f"{x}åˆ†",
        horizontal=True,
        key=f"radio_{qid}_{slug}"
    )
    responses.append({"ID": slug, "title": row.get("title", ""), "score_truth": score})

# ====== é€‰æ‹©é¢˜æ›¿ä»£å¼€æ”¾é¢˜ ======
st.header("ä¸‰ã€é€‰æ‹©é¢˜ï¼ˆåŸºäºå‰è¿°æ–°é—»ï¼‰")
titles = [f"æ–°é—» {r['ID']}ï¼š{r['title']}" for r in responses]

hesitant_news = st.selectbox("4. å“ªæ¡æ–°é—»çš„çœŸå®æ€§æœ€è®©æ‚¨è¿Ÿç–‘ï¼Ÿ", titles, key="hesitant")
verify_news = st.selectbox("5. æ˜¯å¦æœ‰æŸæ¡æ–°é—»è®©æ‚¨å¼ºçƒˆæƒ³éªŒè¯çœŸå‡ï¼Ÿ", titles, key="verify")
clickbait_news = st.selectbox("6. å“ªæ¡æ–°é—»çš„æ ‡é¢˜æœ€åƒâ€œæ ‡é¢˜å…šâ€ï¼Ÿ", titles + ["æ— "], key="clickbait")

# ====== æäº¤é—®å· ======
if st.button("æäº¤é—®å·"):
    all_success = True
    respondent_uuid = str(uuid.uuid4())
    for r in responses:
        payload = {
            "news_id": r["ID"],
            "title": r["title"],
            "score_truth": r["score_truth"],
            "questionnaire_id": qid,
            "age": age,
            "education": edu,
            "freq": freq,
            "hesitant_news": hesitant_news,
            "verify_news": verify_news,
            "clickbait_news": clickbait_news,
            "respondent_uuid": respondent_uuid
        }
        try:
            res = requests.post(GOOGLE_SCRIPT_URL, json=payload)
            if res.status_code != 200:
                all_success = False
        except:
            all_success = False

    # æœ¬åœ° CSV å¤‡ä»½
    out_file = "responses.csv"
    resp_df = pd.DataFrame(responses)
    resp_df["questionnaire_id"] = qid
    resp_df["age"] = age
    resp_df["education"] = edu
    resp_df["freq"] = freq
    resp_df["hesitant_news"] = hesitant_news
    resp_df["verify_news"] = verify_news
    resp_df["clickbait_news"] = clickbait_news
    resp_df["timestamp"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    resp_df["respondent_uuid"] = respondent_uuid

    if not os.path.exists(out_file):
        resp_df.to_csv(out_file, index=False, encoding="utf-8")
    else:
        resp_df.to_csv(out_file, index=False, mode="a", header=False, encoding="utf-8")

    if all_success:
        st.success("âœ… æ•°æ®å·²æˆåŠŸä¸Šä¼ åˆ° Google Sheetsï¼")
    else:
        st.warning("âš ï¸ ä¸Šä¼ éƒ¨åˆ†æ•°æ®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– Apps Script é…ç½®ã€‚")
    st.info("ç³»ç»Ÿå·²å°†æ¯æ¡æ–°é—»æ‰“åˆ†ä¸Šä¼ è‡³ Google Sheetsï¼Œå¹¶ä¿å­˜åœ¨æœ¬åœ°å¤‡ä»½ã€‚")

